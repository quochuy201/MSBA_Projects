{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local[*]) created by __init__ at <ipython-input-1-268736d1964f>:9 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-268736d1964f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecommendation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mALS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'local[*]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark/python/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \"\"\"\n\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callsite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_spark_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mCallSite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    306\u001b[0m                         \u001b[0;34m\" created by %s at %s:%s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m                         % (currentAppName, currentMaster,\n\u001b[0;32m--> 308\u001b[0;31m                             callsite.function, callsite.file, callsite.linenum))\n\u001b[0m\u001b[1;32m    309\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                     \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local[*]) created by __init__ at <ipython-input-1-268736d1964f>:9 "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import pyspark\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.mllib.recommendation import ALS\n",
    "import math\n",
    "sc = pyspark.SparkContext('local[*]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting data sources from url\n",
    "complete_dataset_url = 'http://files.grouplens.org/datasets/movielens/ml-latest.zip'\n",
    "small_dataset_url = 'http://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
    "\n",
    "#create dataset path\n",
    "datasets_path = os.path.join('..', 'work')\n",
    "complete_dataset_path = os.path.join(datasets_path, 'ml-latest.zip')\n",
    "small_dataset_path = os.path.join(datasets_path, 'ml-latest-small.zip')\n",
    "\n",
    "small_f = urllib.request.urlretrieve(small_dataset_url, small_dataset_path)\n",
    "complete_f = urllib.request.urlretrieve (complete_dataset_url, complete_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract zipfile\n",
    "with zipfile.ZipFile(small_dataset_path, \"r\") as z:\n",
    "    z.extractall(datasets_path)\n",
    "\n",
    "with zipfile.ZipFile(complete_dataset_path, \"r\") as z:\n",
    "    z.extractall(datasets_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['userId,movieId,rating,timestamp',\n",
       " '1,1,4.0,964982703',\n",
       " '1,3,4.0,964981247',\n",
       " '1,6,4.0,964982224',\n",
       " '1,47,5.0,964983815']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting small rating file\n",
    "small_ratings_file = os.path.join(datasets_path, 'ml-latest-small', 'ratings.csv')\n",
    "small_ratings_raw_data = sc.textFile(small_ratings_file)\n",
    "small_ratings_raw_data_header = small_ratings_raw_data.take(1)[0]\n",
    "small_ratings_raw_data.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data from rating and movies files\n",
    "def map_rating(path, folder, file):\n",
    "    ratings_file = os.path.join(path, folder, file)\n",
    "    \n",
    "    ratings_raw_data = sc.textFile(ratings_file)\n",
    "    \n",
    "    ratings_raw_data_header = ratings_raw_data.take(1)[0]\n",
    "    \n",
    "    ratings_raw_data.take(5)\n",
    "    \n",
    "    ratings_data = ratings_raw_data.filter(lambda line: line!=ratings_raw_data_header)\\\n",
    "    .map(lambda line: line.split(\",\")).map(lambda tokens: (int(tokens[0]),int(tokens[1]),float(tokens[2]))).cache()\n",
    "    return(ratings_data)\n",
    "\n",
    "def map_movie(path, folder, file):\n",
    "    movies_file = os.path.join(path, folder, file)\n",
    "    \n",
    "    movies_raw_data = sc.textFile(movies_file)\n",
    "    \n",
    "    movies_raw_data_header = movies_raw_data.take(1)[0]\n",
    "    \n",
    "    movies_data = movies_raw_data.filter(lambda line: line!= movies_raw_data_header)\\\n",
    "   .map(lambda line: line.split(\",\")).map(lambda tokens: (tokens[0],tokens[1],tokens[2])).cache()\n",
    "    return(movies_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1, 4.0),\n",
       " (1, 3, 4.0),\n",
       " (1, 6, 4.0),\n",
       " (1, 47, 5.0),\n",
       " (1, 50, 5.0),\n",
       " (1, 70, 3.0),\n",
       " (1, 101, 5.0),\n",
       " (1, 110, 4.0),\n",
       " (1, 151, 5.0),\n",
       " (1, 157, 5.0)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_ratings_data = map_rating(datasets_path, 'ml-latest-small', 'ratings.csv')\n",
    "\n",
    "small_ratings_data.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', 'Toy Story (1995)'),\n",
       " ('2', 'Jumanji (1995)'),\n",
       " ('3', 'Grumpier Old Men (1995)'),\n",
       " ('4', 'Waiting to Exhale (1995)'),\n",
       " ('5', 'Father of the Bride Part II (1995)'),\n",
       " ('6', 'Heat (1995)'),\n",
       " ('7', 'Sabrina (1995)'),\n",
       " ('8', 'Tom and Huck (1995)'),\n",
       " ('9', 'Sudden Death (1995)'),\n",
       " ('10', 'GoldenEye (1995)')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# process movie file\n",
    "small_movies_data =  map_movie(datasets_path, 'ml-latest-small', 'movies.csv')\n",
    "small_movies_data.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting ALS parameters using the small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into train, validate, and test data set\n",
    "training_RDD, validation_RDD, test_RDD = small_ratings_data.randomSplit([6, 2, 2], seed=0)\n",
    "validation_for_predict_RDD = validation_RDD.map(lambda x: (x[0], x[1]))\n",
    "test_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rank 4 the RMSE is 0.908078105265682\n",
      "For rank 8 the RMSE is 0.916462973348527\n",
      "For rank 12 the RMSE is 0.917665030756129\n",
      "The best model was trained with rank 4\n"
     ]
    }
   ],
   "source": [
    "# training phrase\n",
    "# fix parameter.\n",
    "seed = 5\n",
    "iterations = 10\n",
    "regularization_parameter = 0.1\n",
    "ranks = [4, 8, 12]\n",
    "errors = [0, 0, 0]\n",
    "err = 0\n",
    "tolerance = 0.02\n",
    "\n",
    "min_error = float('inf')\n",
    "best_rank = -1\n",
    "best_iteration = -1\n",
    "for rank in ranks:\n",
    "    model = ALS.train(training_RDD, rank, seed=seed, iterations=iterations,\n",
    "                      lambda_=regularization_parameter)\n",
    "    predictions = model.predictAll(validation_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "    rates_and_preds = validation_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "    error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    errors[err] = error\n",
    "    err += 1\n",
    "    print('For rank %s the RMSE is %s' % (rank, error))\n",
    "    if error < min_error:\n",
    "        min_error = error\n",
    "        best_rank = rank\n",
    "\n",
    "print('The best model was trained with rank %s' % best_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((372, 1084), 3.42419871162954),\n",
       " ((4, 1084), 3.866749726695713),\n",
       " ((402, 1084), 3.4099577968422152)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((1, 457), (5.0, 4.381060760461434)),\n",
       " ((1, 1025), (5.0, 4.705295366590298)),\n",
       " ((1, 1089), (5.0, 4.979982471805129))]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rates_and_preds.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For testing data the RMSE is 0.9113780946334407\n"
     ]
    }
   ],
   "source": [
    "model = ALS.train(training_RDD, best_rank, seed=seed, iterations=iterations,\n",
    "                      lambda_=regularization_parameter)\n",
    "predictions = model.predictAll(test_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "rates_and_preds = test_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    \n",
    "print('For testing data the RMSE is %s' % (error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the complete dataset to build the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 100836 recommendations in the complete dataset\n"
     ]
    }
   ],
   "source": [
    "# loaf complete rating data\n",
    "complete_ratings_data = map_rating(datasets_path, 'ml-latest', 'ratings.csv')\n",
    "complete_movies_data =  map_movie(datasets_path, 'ml-latest', 'movies.csv')    \n",
    "print(\"There are %s recommendations in the complete dataset\" % (complete_ratings_data.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model\n",
    "training_RDD, test_RDD = complete_ratings_data.randomSplit([7, 3], seed=0)\n",
    "complete_model = ALS.train(training_RDD, best_rank, seed=seed, \n",
    "                           iterations=iterations, lambda_=regularization_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For testing data the RMSE is 0.8949959237223808\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "test_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1]))\n",
    "\n",
    "predictions = complete_model.predictAll(test_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "rates_and_preds = test_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    \n",
    "print('For testing data the RMSE is %s' % (error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 58098 movies in the complete dataset\n"
     ]
    }
   ],
   "source": [
    "complete_movies_titles = complete_movies_data.map(lambda x: (int(x[0]),x[1]))\n",
    "\n",
    "print(\"There are %s movies in the complete dataset\" % (complete_movies_titles.count()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts_and_averages(ID_and_ratings_tuple):\n",
    "    nratings = len(ID_and_ratings_tuple[1])\n",
    "    return ID_and_ratings_tuple[0], (nratings, float(sum(x for x in ID_and_ratings_tuple[1]))/nratings)\n",
    "\n",
    "movie_ID_with_ratings_RDD = (complete_ratings_data.map(lambda x: (x[1], x[2])).groupByKey())\n",
    "movie_ID_with_avg_ratings_RDD = movie_ID_with_ratings_RDD.map(get_counts_and_averages)\n",
    "movie_rating_counts_RDD = movie_ID_with_avg_ratings_RDD.map(lambda x: (x[0], x[1][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6, 102),\n",
       " (50, 204),\n",
       " (70, 55),\n",
       " (110, 237),\n",
       " (216, 49),\n",
       " (260, 251),\n",
       " (296, 307),\n",
       " (316, 140),\n",
       " (356, 329),\n",
       " (362, 34)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_rating_counts_RDD.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding new user ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New user ratings: [(0, 111, 1), (0, 165, 4), (0, 112556, 5), (0, 122892, 5), (0, 122898, 3), (0, 362, 2), (0, 125916, 3), (0, 539, 3), (0, 329, 5), (0, 858, 5)]\n"
     ]
    }
   ],
   "source": [
    "new_user_ID = 0\n",
    "# The format of each line is (userID, movieID, rating)\n",
    "new_user_ratings = [\n",
    "     (0,111,1), # 'Taxi Driver (1976)'\n",
    "     (0,165,4), # 165, 'Die Hard: With a Vengeance (1995)'\n",
    "     (0,112556,5), # Gone Girl (2014)'\n",
    "     (0,122892,5), # 122892,Avengers: Age of Ultron (2015)\n",
    "     (0,122898,3), # 122898,Justice League (2017)\n",
    "     (0,362,2), # 362, '\"Jungle Book'\n",
    "     (0,125916,3), # 125916,Fifty Shades of Grey '\n",
    "     (0,539,3), # 539, 'Sleepless in Seattle (1993)\n",
    "     (0,329,5) , # 329, 'Star Trek: Generations (1994)'\n",
    "     (0,858,5) # 858, '\"Godfather'\n",
    "    ]\n",
    "new_user_ratings_RDD = sc.parallelize(new_user_ratings)\n",
    "print('New user ratings: %s' % new_user_ratings_RDD.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data_with_new_ratings_RDD = complete_ratings_data.union(new_user_ratings_RDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New model trained in 2.45 seconds\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "t0 = time()\n",
    "new_ratings_model = ALS.train(complete_data_with_new_ratings_RDD, best_rank, seed=seed, \n",
    "                              iterations=iterations, lambda_=regularization_parameter)\n",
    "tt = time() - t0\n",
    "\n",
    "print (\"New model trained in %s seconds\" % round(tt,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting top recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_ratings_ids = map(lambda x: x[1], new_user_ratings) # get just movie IDs\n",
    "# keep just those not on the ID list (thanks Lei Li for spotting the error!)\n",
    "new_user_unrated_movies_RDD = (complete_movies_data.filter(lambda x: x[0] not in new_user_ratings_ids).map(lambda x: (new_user_ID, x[0])))\n",
    "\n",
    "# Use the input RDD, new_user_unrated_movies_RDD, with new_ratings_model.predictAll() to predict new ratings for the movies\n",
    "new_user_recommendations_RDD = new_ratings_model.predictAll(new_user_unrated_movies_RDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4992, ((4.065143061238492, 'Kate & Leopold (2001)'), 17)),\n",
       " (7572, ((5.405579736703817, 'Wit (2001)'), 1)),\n",
       " (5688, ((3.562487664595012, 'Tully (2000)'), 2))]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform new_user_recommendations_RDD into pairs of the form (Movie ID, Predicted Rating)\n",
    "new_user_recommendations_rating_RDD = new_user_recommendations_RDD.map(lambda x: (x.product, x.rating))\n",
    "new_user_recommendations_rating_title_and_count_RDD = \\\n",
    "    new_user_recommendations_rating_RDD.join(complete_movies_titles).join(movie_rating_counts_RDD)\n",
    "new_user_recommendations_rating_title_and_count_RDD.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define userfunction for all steps\n",
    "\n",
    "# split dataset\n",
    "def split_dataset(dataset):\n",
    "    training_RDD, validation_RDD, test_RDD = dataset.randomSplit([6, 2, 2], seed=0)\n",
    "    validation_for_predict_RDD = validation_RDD.map(lambda x: (x[0], x[1]))\n",
    "    test_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1]))\n",
    "    return(training_RDD,validation_RDD,test_RDD,validation_for_predict_RDD,test_for_predict_RDD)\n",
    "\n",
    "# select best ranks:\n",
    "def select_bestranks(training, validation, validation_for_predict):\n",
    "    seed = 5\n",
    "    iterations = 10\n",
    "    regularization_parameter = 0.1\n",
    "    ranks = [4, 8, 12]\n",
    "    errors = [0, 0, 0]\n",
    "    err = 0\n",
    "    tolerance = 0.02\n",
    "\n",
    "    min_error = float('inf')\n",
    "    best_rank = -1\n",
    "    best_iteration = -1\n",
    "    for rank in ranks:\n",
    "        model = ALS.train(training, rank, seed= seed, iterations= iterations, lambda_= regularization_parameter)\n",
    "        predictions = model.predictAll(validation_for_predict).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "        rates_and_preds = validation.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "        error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "        errors[err] = error\n",
    "        err += 1\n",
    "        if error < min_error:\n",
    "            min_error = error\n",
    "            best_rank = rank\n",
    "\n",
    "    return(best_rank)\n",
    "\n",
    "# train model\n",
    "#seed = 5\n",
    "#iterations = 10\n",
    "#regularization_parameter = 0.1\n",
    "#ranks = [4, 8, 12]\n",
    "#errors = [0, 0, 0]\n",
    "#err = 0\n",
    "#tolerance = 0.02\n",
    "def train_model(data, best_rank):\n",
    "    model = ALS.train(data, best_rank, seed=seed, iterations=iterations, lambda_= regularization_parameter)\n",
    "    return(model)\n",
    "# testing\n",
    "def test_model(model, test_for_predict, test):\n",
    "    predictions = model.predictAll(test_for_predict).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "    rates_and_preds = test.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "    error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    return(error)\n",
    "\n",
    "# movie rating count\n",
    "def move_ratcnt(ratings_data):\n",
    "    movie_ID_with_ratings = (ratings_data.map(lambda x: (x[1], x[2])).groupByKey())\n",
    "    movie_ID_with_avg_ratings = movie_ID_with_ratings.map(get_counts_and_averages)\n",
    "    movie_rating_counts = movie_ID_with_avg_ratings.map(lambda x: (x[0], x[1][0]))\n",
    "    return(movie_rating_counts)\n",
    "\n",
    "\n",
    "# recommendation\n",
    "def recommendation(model, new_user_ratings, movies_data, movies_titles, movie_rating_counts, new_user_ID):\n",
    "    new_user_ratings_ids = map(lambda x: x[1], new_user_ratings) # get just movie IDs\n",
    "    \n",
    "    # keep just those not on the ID list (thanks Lei Li for spotting the error!)\n",
    "    new_user_unrated_movies_RDD = (movies_data.filter(lambda x: x[0] not in new_user_ratings_ids).map(lambda x: (new_user_ID, x[0])))\n",
    "    \n",
    "    # Use the input RDD, new_user_unrated_movies_RDD, with new_ratings_model.predictAll() to predict new ratings for the movies\n",
    "    new_user_recommendations_RDD = model.predictAll(new_user_unrated_movies_RDD)\n",
    "    \n",
    "    # Transform new_user_recommendations_RDD into pairs of the form (Movie ID, Predicted Rating)\n",
    "    new_user_recommendations_rating_RDD = new_user_recommendations_RDD.map(lambda x: (x.product, x.rating))\n",
    "    new_user_recommendations_rating_title_and_count = new_user_recommendations_rating_RDD.join(movies_titles).join(movie_rating_counts)\n",
    "    new_user_recommendations_rating_title_and_count = \\\n",
    "    new_user_recommendations_rating_title_and_count.map(lambda r: (r[1][0][1], r[1][0][0], r[1][1]))\n",
    "    top_movies = new_user_recommendations_rating_title_and_count.filter(lambda r: r[2]>=25).takeOrdered(25, key=lambda x: -x[1])\n",
    "    return(top_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full function\n",
    "def full_recom(datasets_path, folder, rating_file, movie_file):\n",
    "    # get data\n",
    "    ratings_data = map_rating(datasets_path, folder, rating_file)\n",
    "    movies_data =  map_movie(datasets_path, folder, movie_file)\n",
    "    movies_titles = movies_data.map(lambda x: (int(x[0]),x[1]))\n",
    "    new_user_ID = 0\n",
    "    training, validation, test, validation_for_predict, test_for_predict = split_dataset(ratings_data)\n",
    "    # best rank\n",
    "    best_rank = select_bestranks(training, validation, validation_for_predict)\n",
    "    # union user data + traindata\n",
    "    data_with_new_ratings_RDD = training.union(new_user_ratings_RDD)\n",
    "    # training model\n",
    "    model = train_model(data_with_new_ratings_RDD, best_rank)\n",
    "    # model error rate\n",
    "    RMSE = test_model(model, test_for_predict, test)\n",
    "\n",
    "    movie_rating_counts = move_ratcnt(ratings_data)\n",
    "\n",
    "    recom = recommendation(model, new_user_ratings, movies_data ,movies_titles, movie_rating_counts, 0)\n",
    "    return(RMSE, recom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new data file 30%\n",
    "import random\n",
    "\n",
    "def split_file(percentage=0.70,isShuffle=True,seed=123):\n",
    "    random.seed(seed)\n",
    "    with open(\"ml-latest/ratings.csv\", 'r',encoding=\"utf-8\") as fin, \\\n",
    "         open(\"ml-latest/ratings70.csv\", 'w') as fout70, \\\n",
    "         open(\"ml-latest/ratings30.csv\", 'w') as fout30:\n",
    "\n",
    "        nLines = sum(1 for line in fin)\n",
    "        fin.seek(0)\n",
    "\n",
    "        nTrain = int(nLines*percentage) \n",
    "        nValid = nLines - nTrain\n",
    "\n",
    "        i = 0\n",
    "        for line in fin:\n",
    "            r = random.random() if isShuffle else 0 # so that always evaluated to true when not isShuffle\n",
    "            if (i < nTrain and r < percentage) or (nLines - i > nValid):\n",
    "                fout70.write(line)\n",
    "                i += 1\n",
    "            else:\n",
    "                fout30.write(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying 4 scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Small dataset\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_small, recom_small = full_recom(datasets_path,'ml-latest-small','ratings.csv','movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9132018474248642"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Red Dragon (2002)', 5.762509985863026, 31),\n",
       " ('Slumdog Millionaire (2008)', 5.625623588879715, 71),\n",
       " ('1408 (2007)', 5.61796692330184, 25),\n",
       " ('Star Wars: Episode III - Revenge of the Sith (2005)',\n",
       "  5.547503826871905,\n",
       "  78),\n",
       " ('Ex Machina (2015)', 5.541494116931921, 28),\n",
       " ('Lord of War (2005)', 5.459302189567019, 35),\n",
       " ('\"I', 5.3714544836466445, 61),\n",
       " (\"Pirates of the Caribbean: At World's End (2007)\", 5.369481763618821, 56),\n",
       " ('Big Fish (2003)', 5.3260223641138875, 69),\n",
       " ('Transformers (2007)', 5.30981342942797, 39),\n",
       " ('\"World Is Not Enough', 5.239654752861686, 39),\n",
       " ('Mystery Science Theater 3000: The Movie (1996)', 5.233780094884777, 36),\n",
       " ('Punch-Drunk Love (2002)', 5.227305198631046, 33),\n",
       " ('\"Bone Collector', 5.200058372585449, 25),\n",
       " ('Star Wars: Episode II - Attack of the Clones (2002)',\n",
       "  5.170406443449441,\n",
       "  92),\n",
       " ('True Grit (2010)', 5.166600519131521, 28),\n",
       " ('Captain America: The Winter Soldier (2014)', 5.130851164377033, 31),\n",
       " ('Remember the Titans (2000)', 5.098682129497366, 41),\n",
       " ('\"Planes', 5.081105619131874, 27),\n",
       " ('Finding Forrester (2000)', 5.072114494024403, 28),\n",
       " ('Rogue One: A Star Wars Story (2016)', 5.06464651766596, 27),\n",
       " ('\"Matrix', 5.042128484467539, 278),\n",
       " ('Lucky Number Slevin (2006)', 5.033180788951778, 38),\n",
       " ('Equilibrium (2002)', 5.032022557245875, 44),\n",
       " ('\"Matrix Revolutions', 5.022411682308831, 79)]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recom_small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 30% complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_30, recom_30 = full_recom(datasets_path,'ml-latest','ratings30.csv','movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8265084703240173"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE_30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"Harrison's Flowers (2000)\", 5.253354784163777, 35),\n",
       " ('\"Stoning of Soraya M.', 5.210474668335228, 55),\n",
       " ('Dragon Ball Z: Bardock - The Father of Goku (Doragon bôru Z: Tatta hitori no saishuu kessen - Furiiza ni itonda Z senshi Kakarotto no chichi) (1990)',\n",
       "  5.014820129537917,\n",
       "  27),\n",
       " ('Instructions Not Included (No se Aceptan Devoluciones) (2013)',\n",
       "  4.882053133720186,\n",
       "  32),\n",
       " ('The Hobbit: The Battle of the Five Armies (2014)', 4.814544513662654, 1547),\n",
       " ('\"Hobbit: The Desolation of Smaug', 4.808711867630247, 2418),\n",
       " ('Fallen Art (Sztuka spadania) (2004)', 4.7999751960012444, 44),\n",
       " ('Stargate SG-1 Children of the Gods - Final Cut (2009)',\n",
       "  4.785991065095895,\n",
       "  55),\n",
       " ('August Rush (2007)', 4.784916995693632, 416),\n",
       " ('Doctor Who: The Waters of Mars (2009)', 4.783987321918712, 115),\n",
       " ('Barbarians at the Gate (1993)', 4.762796649930198, 27),\n",
       " ('Only the Brave (2017)', 4.7429898128138355, 62),\n",
       " ('\"Lord of the Rings: The Two Towers', 4.736673685726939, 17064),\n",
       " ('\"Lord of the Rings: The Return of the King', 4.736428629000153, 17253),\n",
       " ('\"Hobbit: An Unexpected Journey', 4.723573514953918, 3247),\n",
       " ('Inception (2010)', 4.722837606263051, 12493),\n",
       " (\"Serial (Bad) Weddings (Qu'est-ce Qu'on An Fit Au Bon Dieu?) (2014)\",\n",
       "  4.720272435068328,\n",
       "  45),\n",
       " ('Star Trek Into Darkness (2013)', 4.718969671087174, 2301),\n",
       " ('Gladiator (2000)', 4.712828175554796, 14639),\n",
       " ('Foo Fighters: Back and Forth (2011)', 4.706025247492526, 27),\n",
       " ('Jersey Girl (1992)', 4.704207915392545, 33),\n",
       " ('\"Dark Knight Rises', 4.697958882303199, 5944),\n",
       " ('\"Names of Love', 4.697921849465213, 27),\n",
       " ('Way Out West (1937)', 4.696591269200579, 26),\n",
       " ('Sherlock Holmes: A Game of Shadows (2011)', 4.693898766379014, 2642)]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recom_30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 70% complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_70, recom_70 = full_recom(datasets_path,'ml-latest','ratings70.csv','movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8166786814742976"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE_70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Foo Fighters: Back and Forth (2011)', 5.107764176493012, 35),\n",
       " ('Two Rabbits (2 Coelhos) (2012)', 5.047183258092536, 34),\n",
       " ('Who Am I (Kein System Ist Sicher) (2014)', 4.986711935609485, 249),\n",
       " ('The Reichenbach Fall (2012)', 4.935866879148645, 30),\n",
       " ('Jim Jefferies: Freedumb (2016)', 4.852225367396554, 62),\n",
       " ('Rock the Kasbah (2015)', 4.808769405690816, 51),\n",
       " ('The Lost Room (2006)', 4.796616582134121, 196),\n",
       " ('Cranford (2007)', 4.785157644628979, 27),\n",
       " ('\"Fuck You', 4.7785663022519556, 75),\n",
       " ('The Glass Castle', 4.748164410795484, 54),\n",
       " ('Sherlock - A Study in Pink (2010)', 4.737348106967002, 153),\n",
       " ('\"Matrix', 4.735215369795464, 59186),\n",
       " ('Till Human Voices Wake Us (2001)', 4.73009809265276, 34),\n",
       " ('Inception (2010)', 4.729145095434363, 28982),\n",
       " ('Bunraku (2010)', 4.7234350159123775, 79),\n",
       " ('The Matrix Revisited (2001)', 4.713674298908891, 40),\n",
       " ('We Are The Night (Wir sind die Nacht) (2010)', 4.709029632750187, 28),\n",
       " ('Gladiator (2000)', 4.696818055627896, 34027),\n",
       " ('Bill Hicks: Sane Man (1989)', 4.695416530618941, 33),\n",
       " ('Interstellar (2014)', 4.695144282333427, 16158),\n",
       " ('Law Abiding Citizen (2009)', 4.686191569680739, 1827),\n",
       " ('Black Mirror', 4.679922262759753, 121),\n",
       " ('One Piece Film Z (2012)', 4.676472436124107, 28),\n",
       " ('\"Dark Knight', 4.668939947739535, 31363),\n",
       " ('And Then There Were None (2015)', 4.666496263038457, 69)]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recom_70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_100, recom_100 = full_recom(datasets_path,'ml-latest','ratings.csv','movies.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Cosmos: A Spacetime Odissey', 5.127218844239509, 37),\n",
       " ('Sinatra: All or Nothing at All (2015)', 4.842528159331449, 35),\n",
       " ('The Butterfly Circus (2009)', 4.817608714502535, 28),\n",
       " ('Dragon Ball: Episode of Bardock (2011)', 4.813921035431139, 30),\n",
       " ('Dragon Ball Z: Super Android 13! (Doragon bôru Z 7: Kyokugen batoru!! San dai sûpâ saiyajin) (1992)',\n",
       "  4.79990103247374,\n",
       "  44),\n",
       " ('Dragon Ball Z: Broly Second Coming (Doragon bôru Z 10: Kiken na futari! Sûpâ senshi wa nemurenai) (1994)',\n",
       "  4.795481041673521,\n",
       "  38),\n",
       " ('Loose Change 9/11: An American Coup (2009)', 4.790218227567256, 46),\n",
       " ('Dragon Ball Z: Resurrection of F (2015)', 4.747191956158441, 90),\n",
       " ('The Lost Room (2006)', 4.698187527796, 280),\n",
       " ('DMB (2000)', 4.639759076980306, 29),\n",
       " ('\"Hobbit: The Desolation of Smaug', 4.634019648143463, 7995),\n",
       " ('Doctor Who: Twice Upon A Time (2017)', 4.633733277492968, 65),\n",
       " ('Yolki 2 (2011)', 4.625842867926236, 31),\n",
       " ('Iron Jawed Angels (2004)', 4.621041018653384, 39),\n",
       " ('Adrift (2018)', 4.592939100220273, 49),\n",
       " ('The Hobbit: The Battle of the Five Armies (2014)', 4.58503118613777, 5175),\n",
       " ('Jeff Dunham: Spark of Insanity (2007)', 4.581358230458311, 64),\n",
       " ('Interstellar (2014)', 4.578781595977582, 23081),\n",
       " ('The Red Pill (2016)', 4.5783555558077085, 46),\n",
       " ('Validation (2007)', 4.574402433419236, 31),\n",
       " ('Law Abiding Citizen (2009)', 4.570819441658123, 2570),\n",
       " ('Act of Valor (2012)', 4.565873272184337, 390),\n",
       " ('\"Scarlet Pimpernel', 4.559866872956058, 26),\n",
       " ('Aashiqui 2 (2013)', 4.553354476643886, 33),\n",
       " ('Silenced (2011)', 4.540907055154921, 35)]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recom_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8199886721277755"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
